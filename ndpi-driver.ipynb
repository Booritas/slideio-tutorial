{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "030d2f95-6e00-4f90-accb-8af2c1202251",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import slideio\n",
    "from utils import get_test_images, display_driver_test_image_info, show_images, show_image, get_driver_test_images\n",
    "from IPython.display import display\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99996fed-bbc8-4945-bbe9-b5ceb098b297",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Test images\n",
    "For the future demonstration of the library, we will be utilizing some test images. Information regarding the images and the drivers required for image processing is stored in the *image.json* file. The helper utility *get_test_images* loads this image information into a list for convenient access and utilization during the demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6bebd81-3494-463e-bef2-c3b05c4dc393",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style='border-collapse: collapse'><tr><th style='text-align: left; border: 1px solid black'>Image Path</th><th style='text-align: left; border: 1px solid black'>Driver</th></tr><tr><td style='text-align: left; border: 1px solid black'>./images/test3-DAPI-2-(387).ndpi</td><td style='text-align: left; border: 1px solid black'>NDPI</td></tr><tr><td style='text-align: left; border: 1px solid black'>./images/test3-FITC 2 (485).ndpi</td><td style='text-align: left; border: 1px solid black'>NDPI</td></tr><tr><td style='text-align: left; border: 1px solid black'>./images/test3-TRITC 2 (560).ndpi</td><td style='text-align: left; border: 1px solid black'>NDPI</td></tr><tr><td style='text-align: left; border: 1px solid black'>./images/2017-02-27 15.22.39.ndpi</td><td style='text-align: left; border: 1px solid black'>NDPI</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "images = get_driver_test_images('NDPI')\n",
    "display_driver_test_image_info(images, 'NDPI')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cec15d2-cd54-4d00-bb7d-943e69974a7f",
   "metadata": {},
   "source": [
    "# Overview\n",
    "This notebook demonstrates using slideio library for reading of hammamatsu ndpi images. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d4a2e2-9c57-467d-809a-65b302116dea",
   "metadata": {},
   "source": [
    "# Open hammamatsu image\n",
    "Driver id for the hammamatsu ndpi images is 'NDPI'. Slideio library can automaticaly recognize the image by file extension '.ndpi'. It is possible to use 'AUTO' instead of driver id if a file has extension '.ndpi'. A hammamatsu slide always contain a single scene and up to 2 auxiliary images (macro and map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd74b1b6-5fce-4c51-9fb7-8e35db08d728",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Number of scenes: 1, Auxiliary images: ['macro', 'map']\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slide_path = images[3][\"path\"]\n",
    "slide = slideio.open_slide(slide_path, 'AUTO')\n",
    "f\"Number of scenes: {slide.num_scenes}, Auxiliary images: {slide.get_aux_image_names()}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139d4533-9927-4686-b7d2-2e449b53b254",
   "metadata": {},
   "source": [
    "The single scene is always accessible by index '0'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f52f8528-f751-4081-aa41-ca85805bc9b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0, 7680, 11008)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = slide.get_scene(0)\n",
    "image.rect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a761cb70-885f-483b-b04a-65fd15df9694",
   "metadata": {},
   "source": [
    "NDPI slides can be brightfield JPEG encoded images or single channel 16bit JpegXR compressed images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "910aa934-05dd-4bc2-bcf6-5597d277433d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./images/test3-DAPI-2-(387).ndpi\n",
      "./images/test3-FITC 2 (485).ndpi\n",
      "./images/test3-TRITC 2 (560).ndpi\n",
      "./images/2017-02-27 15.22.39.ndpi\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>num scenes</th>\n",
       "      <th>rect</th>\n",
       "      <th>num channels</th>\n",
       "      <th>compression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./images/test3-DAPI-2-(387).ndpi</td>\n",
       "      <td>1</td>\n",
       "      <td>(0, 0, 3968, 4864)</td>\n",
       "      <td>3</td>\n",
       "      <td>Compression.Jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./images/test3-FITC 2 (485).ndpi</td>\n",
       "      <td>1</td>\n",
       "      <td>(0, 0, 3968, 4864)</td>\n",
       "      <td>3</td>\n",
       "      <td>Compression.Jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./images/test3-TRITC 2 (560).ndpi</td>\n",
       "      <td>1</td>\n",
       "      <td>(0, 0, 3968, 4864)</td>\n",
       "      <td>3</td>\n",
       "      <td>Compression.Jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./images/2017-02-27 15.22.39.ndpi</td>\n",
       "      <td>1</td>\n",
       "      <td>(0, 0, 7680, 11008)</td>\n",
       "      <td>3</td>\n",
       "      <td>Compression.Jpeg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                path  num scenes                 rect   \n",
       "0   ./images/test3-DAPI-2-(387).ndpi           1   (0, 0, 3968, 4864)  \\\n",
       "0   ./images/test3-FITC 2 (485).ndpi           1   (0, 0, 3968, 4864)   \n",
       "0  ./images/test3-TRITC 2 (560).ndpi           1   (0, 0, 3968, 4864)   \n",
       "0  ./images/2017-02-27 15.22.39.ndpi           1  (0, 0, 7680, 11008)   \n",
       "\n",
       "   num channels       compression  \n",
       "0             3  Compression.Jpeg  \n",
       "0             3  Compression.Jpeg  \n",
       "0             3  Compression.Jpeg  \n",
       "0             3  Compression.Jpeg  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows = []\n",
    "for image_item in images:\n",
    "    image_path = image_item[\"path\"]\n",
    "    image_data = {}\n",
    "    print(image_path)\n",
    "    image_data[\"path\"] = image_path\n",
    "    slide = slideio.open_slide(image_path, 'NDPI')\n",
    "    image_data[\"num scenes\"] = slide.num_scenes\n",
    "    scene = slide.get_scene(0)\n",
    "    image_data[\"rect\"] = str(scene.rect)\n",
    "    channel_count = scene.num_channels\n",
    "    image_data[\"num channels\"] = channel_count\n",
    "    #image_data[\"channel type\"] = str(scene.get_channel_data_type(0))\n",
    "    image_data[\"compression\"] = str(scene.compression)\n",
    "    row_df = pd.DataFrame([image_data])\n",
    "    rows.append(row_df)\n",
    "df = pd.concat(rows)    \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f286c86-e12c-44be-b80b-aaf4ecc0e360",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
